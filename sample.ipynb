{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COSMO\n",
    "\n",
    "COSMO is a conversation agent with greater generalizability on both in- and out-of-domain chitchat datasets (e.g., DailyDialog, BlendedSkillTalk). It is trained on two datasets: SODA and ProsocialDialog. COSMO is especially aiming to model natural human conversations. It can accept situation descriptions as well as instructions on what role it should play in the situation.\n",
    "\n",
    "Link: https://github.com/skywalker023/sodaverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /Users/muthuka/Library/Python/3.9/lib/python/site-packages (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/muthuka/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/muthuka/Library/Python/3.9/lib/python/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/muthuka/Library/Python/3.9/lib/python/site-packages (from matplotlib) (4.45.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/muthuka/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /Users/muthuka/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/muthuka/Library/Python/3.9/lib/python/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/muthuka/Library/Python/3.9/lib/python/site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/muthuka/Library/Python/3.9/lib/python/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/muthuka/Library/Python/3.9/lib/python/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/muthuka/Library/Python/3.9/lib/python/site-packages (from matplotlib) (6.1.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/muthuka/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /Users/muthuka/Library/Python/3.9/lib/python/site-packages (2.1.0)\n",
      "Requirement already satisfied: torchvision in /Users/muthuka/Library/Python/3.9/lib/python/site-packages (0.16.0)\n",
      "Requirement already satisfied: torchaudio in /Users/muthuka/Library/Python/3.9/lib/python/site-packages (2.1.0)\n",
      "Requirement already satisfied: filelock in /Users/muthuka/Library/Python/3.9/lib/python/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/muthuka/Library/Python/3.9/lib/python/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /Users/muthuka/Library/Python/3.9/lib/python/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/muthuka/Library/Python/3.9/lib/python/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/muthuka/Library/Python/3.9/lib/python/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/muthuka/Library/Python/3.9/lib/python/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: numpy in /Users/muthuka/Library/Python/3.9/lib/python/site-packages (from torchvision) (1.26.1)\n",
      "Requirement already satisfied: requests in /Users/muthuka/Library/Python/3.9/lib/python/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/muthuka/Library/Python/3.9/lib/python/site-packages (from torchvision) (10.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/muthuka/Library/Python/3.9/lib/python/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/muthuka/Library/Python/3.9/lib/python/site-packages (from requests->torchvision) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/muthuka/Library/Python/3.9/lib/python/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/muthuka/Library/Python/3.9/lib/python/site-packages (from requests->torchvision) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/muthuka/Library/Python/3.9/lib/python/site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/muthuka/Library/Python/3.9/lib/python/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --pre torch torchvision torchaudio \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.0\n",
      "Is MPS (Metal Performance Shader) built? True\n",
      "Is MPS available? True\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check PyTorch has access to MPS (Metal Performance Shader, Apple's GPU architecture)\n",
    "print(f\"Is MPS (Metal Performance Shader) built? {torch.backends.mps.is_built()}\")\n",
    "print(f\"Is MPS available? {torch.backends.mps.is_available()}\")\n",
    "\n",
    "# Set the device      \n",
    "device = \"cpu\" \n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    # Initialize the device\n",
    "    device = \"mps\"\n",
    "    \n",
    "# elif torch.cuda.is_available():\n",
    "#     # Initialize the device\n",
    "#     device = \"cuda\"\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac51455ef072418e95d25653045fef34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# All models are downloaded from HuggingFace\n",
    "device = torch.device(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/cosmo-xl\", legacy=False, use_fast=True)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/cosmo-xl\").to(device)\n",
    "\n",
    "def set_input(situation_narrative, role_instruction, conversation_history):\n",
    "    input_text = \" <turn> \".join(conversation_history)\n",
    "\n",
    "    if role_instruction != \"\":\n",
    "        input_text = \"{} <sep> {}\".format(role_instruction, input_text)\n",
    "\n",
    "    if situation_narrative != \"\":\n",
    "        input_text = \"{} <sep> {}\".format(situation_narrative, input_text)\n",
    "\n",
    "    return input_text\n",
    "\n",
    "def generate(situation_narrative, role_instruction, conversation_history):\n",
    "    \"\"\"\n",
    "    situation_narrative: the description of situation/context with the characters included (e.g., \"David goes to an amusement park\")\n",
    "    role_instruction: the perspective/speaker instruction (e.g., \"Imagine you are David and speak to his friend Sarah\").\n",
    "    conversation_history: the previous utterances in the conversation in a list\n",
    "    \"\"\"\n",
    "\n",
    "    input_text = set_input(situation_narrative, role_instruction, conversation_history) \n",
    "\n",
    "    inputs = tokenizer([input_text], return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(inputs[\"input_ids\"], max_new_tokens=128, temperature=1.0, top_p=.95, do_sample=True)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ask a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was great! I had a lot of fun participating in the EMNLP conference.\n"
     ]
    }
   ],
   "source": [
    "situation = \"Cosmo had a really fun time participating in the EMNLP conference at Abu Dhabi.\"\n",
    "instruction = \"You are Cosmo and you are talking to a friend.\" # You can also leave the instruction empty\n",
    "\n",
    "conversation = [\n",
    "    \"Hey, how was your trip to Abu Dhabi?\"\n",
    "]\n",
    "\n",
    "response = generate(situation, instruction, conversation)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
